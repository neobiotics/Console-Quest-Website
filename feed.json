{
    "version": "https://jsonfeed.org/version/1",
    "title": "Console Quest",
    "description": "",
    "home_page_url": "https://consolequest.net",
    "feed_url": "https://consolequest.net/feed.json",
    "user_comment": "",
    "author": {
        "name": "Juri Steiner"
    },
    "items": [
        {
            "id": "https://consolequest.net/claude-code-docker.html",
            "url": "https://consolequest.net/claude-code-docker.html",
            "title": "Running Claude Code in Docker: Because SSH is All You Need",
            "summary": "Claude Code is excellent. It’s fast, it understands context, and it actually&hellip;",
            "content_html": "<p>Claude Code is excellent. It’s fast, it understands context, and it actually helps you write better code. It even supports remote authentication - you can grab an OAuth token via browser on any device and paste it in. There’s just one tiny problem: I’m weird and want to run it in a Docker container.</p><p>Containers don’t persist login state. Every restart, every rebuild - gone. Back to square one.</p><h2 id=\"why-run-claude-code-in-a-container\">Why Run Claude Code in a Container?</h2>\n<p>Fair question. Why not just run it locally like a normal person?</p><p>Because I work from way too many machines. Sometimes my desktop, sometimes my laptop - shit, maybe even from my work computer during breaks. I wanted one consistent environment I could SSH into from anywhere, with my notes and context already there.</p><p>Also, I’ll be honest: an AI with full access to my machine creeps me out a little. Inside a Docker container? Much better. It can do its thing in there, isolated, and I sleep easier.</p><p>And okay, fine - I also just wanted to see if it was possible.</p><h2 id=\"the-oauth-problem\">The OAuth Problem</h2>\n<p>When you start Claude Code, it asks: Claude subscription or API key?</p><p>Sounds like a choice. It’s not really. Both paths lead to OAuth - just to different endpoints:</p><ul>\n<li><strong>Claude subscription</strong> → OAuth via claude.ai</li>\n<li><strong>API key</strong> → OAuth via console.anthropic.com</li>\n</ul>\n<p>Either way: browser, login, authentication state that doesn’t survive a container restart.</p><p>But here’s the thing - you can set <code>ANTHROPIC_API_KEY</code> as an environment variable, and Claude Code will use it directly. No OAuth. This is actually documented for SDK usage. The catch? It still shows a confirmation dialog asking if you trust this key. In a container that rebuilds, you’d have to confirm every single time.</p><p>Unless you know where it stores that trust. That part isn’t in the docs.</p><h2 id=\"the-trust-config-discovery\">The Trust Config Discovery</h2>\n<p>After some digging (and reading way too much source code), I found that Claude Code stores trusted keys in <code>~/.claude.json</code>. The interesting part? It doesn’t store the full API key - just the last 20 characters for verification.</p><p>This means we can pre-populate the trust config:</p><pre><code class=\"language-json\">{\n  &quot;customApiKeyResponses&quot;: {\n    &quot;approved&quot;: [&quot;...last20chars...&quot;],\n    &quot;rejected&quot;: []\n  },\n  &quot;hasCompletedOnboarding&quot;: true,\n  &quot;hasTrustDialogAccepted&quot;: true\n}\n</code></pre>\n<p>Those flags skip the onboarding flow entirely. No browser needed, no interactive prompts, just straight to work.</p><h2 id=\"building-the-container\">Building the Container</h2>\n<p>The Dockerfile is straightforward - Ubuntu base, SSH server, Claude Code CLI:</p><pre><code class=\"language-dockerfile\">FROM ubuntu:24.04\n\n# System packages\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    openssh-server \\\n    ssh-import-id \\\n    curl git vim htop ripgrep jq \\\n    nodejs npm \\\n    &amp;&amp; rm -rf /var/lists/*\n\n# SSH setup - key-based auth only\nRUN mkdir /var/run/sshd \\\n    &amp;&amp; mkdir -p /root/.ssh \\\n    &amp;&amp; chmod 700 /root/.ssh \\\n    &amp;&amp; echo &quot;PermitRootLogin yes&quot; &gt;&gt; /etc/ssh/sshd_config \\\n    &amp;&amp; echo &quot;PasswordAuthentication no&quot; &gt;&gt; /etc/ssh/sshd_config \\\n    &amp;&amp; echo &quot;PubkeyAuthentication yes&quot; &gt;&gt; /etc/ssh/sshd_config\n\n# Claude Code CLI\nRUN npm install -g @anthropic-ai/claude-code\n\n# Workspace\nRUN mkdir -p /workspace/notes\n\nEXPOSE 22\nENTRYPOINT [&quot;/entrypoint.sh&quot;]\n</code></pre>\n<p>The entrypoint script is where the magic happens - it sets up SSH keys, configures the API key trust, and starts the SSH server:</p><pre><code class=\"language-bash\">#!/bin/bash\nset -e\n\n# Import SSH keys from GitHub\nif [ -n &quot;$GITHUB_USERS&quot; ]; then\n    ssh-import-id-gh ${GITHUB_USERS//,/ }\nfi\n\n# Claude Code API Key Setup\nif [ -n &quot;$ANTHROPIC_API_KEY&quot; ]; then\n    # Make key available in SSH sessions\n    echo &quot;export ANTHROPIC_API_KEY=\\&quot;$ANTHROPIC_API_KEY\\&quot;&quot; &gt;&gt; /root/.bashrc\n    \n    # Extract last 20 characters for trust config\n    ANTHROPIC_API_KEY_LAST_20=&quot;${ANTHROPIC_API_KEY: -20}&quot;\n    \n    # Create trust config\n    cat &lt;&lt;EOF &gt; /root/.claude.json\n{\n  &quot;customApiKeyResponses&quot;: {\n    &quot;approved&quot;: [&quot;$ANTHROPIC_API_KEY_LAST_20&quot;],\n    &quot;rejected&quot;: []\n  },\n  &quot;hasCompletedOnboarding&quot;: true,\n  &quot;hasTrustDialogAccepted&quot;: true\n}\nEOF\nfi\n\n# Start SSH server\nexec /usr/sbin/sshd -D\n</code></pre>\n<p>The <code>ssh-import-id-gh</code> command is criminally underrated - it pulls your public SSH keys directly from GitHub. No manual key management needed.</p><h2 id=\"then-i-wanted-to-push-to-github\">Then I Wanted to Push to GitHub</h2>\n<p>The container worked. Claude Code ran headless. I could SSH in and use it. Perfect.</p><p>Then I made some changes, felt productive, typed <code>git push</code> and… right. SSH keys. In a container. That I didn’t mount.</p><p>Sound familiar? Non-persistent authentication, round two. Apparently I needed to learn this lesson twice.</p><p>The problem is persistence:</p><pre><code class=\"language-yaml\">volumes:\n  - ./notes:/workspace/notes       # ✅ Persistent\n  - ./claude-data:/root/.claude    # ✅ Persistent\n  # But /root/.ssh?                # ❌ NOT mounted = gone on restart\n</code></pre>\n<p>SSH keys stored in <code>/root/.ssh</code> disappear on container restart. I could mount that directory too, but there’s a simpler solution: Git credential helper with a persistent location.</p><pre><code class=\"language-bash\">git config --global credential.helper &#39;store --file=/root/.claude/.git-credentials&#39;\n</code></pre>\n<p>Since <code>/root/.claude</code> is already bind-mounted, the credentials file survives container restarts. On first push, Git asks for credentials - I enter my GitHub Personal Access Token - and it’s stored. Every subsequent push works automatically.</p><p>This actually feels cleaner than SSH keys for containers. The token is revocable from GitHub’s settings, it doesn’t require key generation, and it works identically across any machine. Sometimes the workaround becomes the better solution.</p><h2 id=\"the-final-setup\">The Final Setup</h2>\n<p>Here’s the complete docker-compose configuration:</p><pre><code class=\"language-yaml\">services:\n  claude-code:\n    build: ./claude-ssh\n    container_name: claude-code\n    ports:\n      - &quot;2222:22&quot;\n    volumes:\n      - ./notes:/workspace/notes\n      - ./claude-data:/root/.claude\n    environment:\n      - GITHUB_USERS=${GITHUB_USERS}\n      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}\n    restart: unless-stopped\n</code></pre>\n<p>With a <code>.env</code> file:</p><pre><code class=\"language-bash\">GITHUB_USERS=your-github-username\nANTHROPIC_API_KEY=sk-ant-xxxxx\n</code></pre>\n<p>That’s it. Run <code>docker compose up -d --build</code>, wait about 5 minutes for npm to install Claude Code, then:</p><pre><code class=\"language-bash\">ssh -p 2222 root@your-server\ncd /workspace/notes\nclaude\n</code></pre>\n<p>No OAuth flow. No onboarding. No manual SSH key setup. Just Claude Code, ready to use, with working Git integration.</p><h2 id=\"bonus-pairing-with-a-markdown-editor\">Bonus: Pairing with a Markdown Editor</h2>\n<p>I run this alongside <a href=\"https://github.com/gamosoft/notediscovery\">NoteDiscovery</a>, a simple web UI for browsing Markdown files:</p><pre><code class=\"language-yaml\">services:\n  notediscovery:\n    image: ghcr.io/gamosoft/notediscovery:latest\n    ports:\n      - &quot;8800:8000&quot;\n    volumes:\n      - ./notes:/app/data\n\n  claude-code:\n    # ... as above\n</code></pre>\n<p>Both containers share the same notes directory. I browse and organize in the web UI, edit with Claude Code via SSH. It’s simple, it works, and I can access it from anywhere.</p><h2 id=\"current-setup\">Current Setup</h2>\n<blockquote>\n<p><strong>Container Platform:</strong> Docker Compose on TrueNAS Scale → Dockge for management</p></blockquote>\n<blockquote>\n<p><strong>Claude Code:</strong> Latest version via npm global install → API key auth, OAuth bypassed</p></blockquote>\n<blockquote>\n<p><strong>SSH Access:</strong> Port 2222 exposed → Keys automatically pulled from GitHub</p></blockquote>\n<blockquote>\n<p><strong>Persistence:</strong> Two bind mounts → notes/ and .claude/ directory, credentials survive restarts</p></blockquote>\n<blockquote>\n<p><strong>Git Integration:</strong> Personal Access Token → Stored in persistent location, works across rebuilds</p></blockquote>\n<blockquote>\n<p><strong>Companion Service:</strong> NoteDiscovery web UI → Same notes volume, different access method</p></blockquote>\n<h2 id=\"whats-next\">What’s Next</h2>\n<p>The setup works. But man, this thing churns through tokens like crazy. From jumping into the SSH session to pushing the <a href=\"https://github.com/neobiotics/claude-markdown-workspace\">GitHub repo</a> - okay, and making it barely presentable to the whole internet - five bucks were gone. </p><p>So I’m looking at <a href=\"https://github.com/anomalyco/opencode\">opencode</a> as an alternative. It has multi-provider support, so I could use cheaper models for simple tasks. Native web UI too, which might eliminate the SSH dance entirely. And maybe a Code Server container bolted on sideways at some point. We’ll see.</p><p>The whole setup is <a href=\"https://github.com/neobiotics/claude-markdown-workspace\">published on GitHub</a> if you want the complete config.</p><hr>\n<p><em>What’s your remote development setup look like? Are you running AI coding assistants in containers, or am I the only one who thought SSH-ing into a TUI was a good idea?</em></p>",
            "image": "https://consolequest.net/media/posts/8/Gemini_Generated_Image_fqvcf6fqvcf6fqvc-1.png",
            "author": {
                "name": "Juri Steiner"
            },
            "tags": [
                   "selfhosting",
                   "documentation",
                   "docker"
            ],
            "date_published": "2026-01-11T14:38:33+01:00",
            "date_modified": "2026-01-11T14:44:55+01:00"
        },
        {
            "id": "https://consolequest.net/the-backlog-of-doom-my-queue-of-ill-document-that-later-projects-2.html",
            "url": "https://consolequest.net/the-backlog-of-doom-my-queue-of-ill-document-that-later-projects-2.html",
            "title": "The Backlog of Doom: My Queue of &quot;I&#x27;ll Document That Later&quot; Projects",
            "summary": "You know what’s worse than having a messy homelab? Having a messy&hellip;",
            "content_html": "<p>You know what’s worse than having a messy homelab? Having a messy homelab that you haven’t documented yet. And you know what’s even worse than that? Publishing a blog post about all the things you haven’t documented, creating a public record of your procrastination.</p><p>So here we are.</p><h2 id=\"the-current-situation\">The Current Situation</h2>\n<p>I’ve got three TrueNAS servers, a UniFi network setup that’s probably overkill for a home environment, way too many Docker containers (still haven’t counted past 47), and a Home Assistant instance that controls more entities than I’d like to admit. And guess what? Almost none of it is properly documented.</p><p>Sure, I’ve got some scattered notes. A few Docker Compose files with comments like “did this because of that” Some mental notes about why I configured things a certain way. But actual documentation? The kind someone else could read and understand? Yeah, about that…</p><h2 id=\"the-i-need-to-document-this-yesterday-list\">The “I Need To Document This Yesterday” List</h2>\n<p>Let me break down what’s currently running undocumented in my infrastructure:</p><blockquote>\n<p><strong>Hardware Inventory:</strong> Three servers, various switches and APs → Honestly, it’s not going anywhere - I can just walk to the basement and look at it</p></blockquote>\n<p>The hardware is probably the easiest to document since it’s in a relatively finished state. It’s sitting there, doing its job, consuming electricity. At least if I forget what CPU is in which box, I can physically go look. But “finished” deserves documentation, right?</p><blockquote>\n<p><strong>Network Infrastructure:</strong> UniFi Gateway, Controller, switches, APs → The only thing truly “prod” in this setup - entire household depends on it</p></blockquote>\n<p>This is the one piece of infrastructure I’d actually call production-ready. It’s functional, optimized, and the whole household relies on it. When someone complains the internet is down, this is what I’m troubleshooting. It works well enough that I have planned changes and extensions, which is exactly why it’s appearing both in the “document what exists” and “projects to finish” categories.</p><blockquote>\n<p><strong>Smart Home:</strong> Home Assistant + various integrations → Works great, saves real money, but has rough edges I don’t discuss at parties</p></blockquote>\n<p>Here’s where it gets interesting. My Home Assistant setup barely makes this list because it <em>technically</em> works. The regular “lightswitch users” in my household don’t notice anything weird. In fact, they even get some comfort features they didn’t ask for. Most importantly, it’s saving actual money with automations around PV, power-to-heat, and heating.</p><p>But here’s the thing: it has so much more potential. There are rough edges. There are downright broken automations. Neglected integrations. Obsolete entities from experiments I forgot to clean up. If I’m being honest with myself - which apparently I am, in public, on the internet - this thing could use some serious attention.</p><h2 id=\"the-i-started-but-never-finished-projects\">The “I Started But Never Finished” Projects</h2>\n<p>Then there’s the category of projects I began with enthusiasm and then… didn’t finish:</p><p><strong>Network Segmentation &amp; Security Overhaul</strong><br>Even though my UniFi setup is production-stable, I have changes and extensions planned. Controller settings, Gateway configs, switch configurations, DNS setup, IDS/IPS rules. It’s all configured and working, but documenting it <em>before</em> making changes seems wise. Novel concept, I know. What am I planning to change? Proper network segmentation, a DMZ, VLANs with purpose, an IoT network with tailored radio settings, maybe even outbound firewall rules. You know, the stuff you read about and think “I should really do that properly.”</p><p><strong>Storage Architecture &amp; Backup Strategy Rework</strong><br>I’m currently in the midst of migrating folders for my Docker containers to separate datasets, optimized for the workload - databases on the SSD pool with appropriate record sizes, that sort of thing. The structure I’ve created is already too complicated, and I know it. Backups of irretrievable data exist, sure, but they follow no stringent logic and aren’t sensibly aligned with snapshot schedules. This all needs some Gehirnschmalz before it spirals further out of control.</p><p><strong>Smart Home Deep Dive</strong><br>This deserves its own post. Or maybe a series. Between the money-saving automations that work brilliantly and the abandoned experiments cluttering up my entity list, there’s a lot to unpack here.</p><h2 id=\"the-ambitious-plans-that-havent-started-category\">The “Ambitious Plans That Haven’t Started” Category</h2>\n<p>And then we have the projects that exist purely in the “this would be cool” phase:</p><p><strong>Centralized Logging (Graylog)</strong><br>Because apparently having logs scattered across multiple containers isn’t enterprise enough. I want to actually <em>aggregate</em> them and maybe even <em>search</em> them like a proper infrastructure.</p><p><strong>XDR/SIEM with Wazuh</strong><br>At some point, my homelab crossed the line from “hobby project” to “I should probably know if something suspicious is happening.” Wazuh keeps getting added to my “eventually” list.</p><p><strong>Remote Access Revamp (Netbird)</strong><br>Tailscale works, and I actually love it, but it always felt more at home at work. Netbird seems like it might fit better for a home setup. Plus, I want to give family members secure access to certain services without them needing a degree in networking.</p><p><strong>Long-term Data Retention (InfluxDB)</strong><br>I’m collecting metrics. Some of them are interesting. Some of them disappear after 30 days. InfluxDB would fix this, but it’s been on my list for months.</p><p><strong>Getting Actual Insights from My Data</strong><br>This is the ambitious one. Take all my data - logs, metrics, documents from Paperless-ngx, everything - and actually make it searchable and analyzable. RAG, knowledge graphs, maybe some ML. Yes, I know this sounds like I’m trying to build my own AI assistant. No, I haven’t started yet.</p><p><strong>N8N Workflow Automation</strong><br>Okay, maybe I <em>am</em> building my own AI assistant. N8N would tie everything together - automations that span services, intelligent workflows, data processing pipelines. It’s sitting on my “sounds amazing but haven’t installed it” list.</p><p><strong>Blog Analytics &amp; Comments</strong><br>Adding analytics and a comment section to this blog. Because scientifically speaking, zero readers and <em>exactly</em> zero readers are different things. Plus, this way I’m guaranteed to finally be the first person to comment on something for once.</p><p><strong>Home Energy Management System (HEMS)</strong><br>Solar, battery, heat pump, various loads, and §14a Module 3 compliance. For those not familiar with German energy regulations: this is about getting money back from the grid operator by giving them the ability to control certain devices during peak demand. It’s the project that keeps growing in scope every time I think about it. Integration of everything energy-related into one coherent system that actually optimizes for cost and grid stability.</p><h2 id=\"why-im-publishing-this\">Why I’m Publishing This</h2>\n<p>Two reasons:</p><p>First, public accountability. If I tell the internet (all zero of you reading this) that I’m going to document something, maybe I’ll actually do it.</p><p>Second, maybe someone else is in the same boat. Maybe you’ve also got a working setup that exists primarily in your memory and would take weeks to properly document. Maybe you’ve got automations saving you money while other automations from 2023 are still lingering in your config, disabled but not deleted. Maybe we can suffer through this together.</p><h2 id=\"the-plan-such-as-it-is\">The Plan (Such As It Is)</h2>\n<p>I’m going to tackle these in some semblance of order. Starting with documenting what’s already working, then finishing the half-done projects, then maybe - <em>maybe</em> - starting the ambitious new stuff.</p><p>But let’s be honest, I’ll probably get distracted by a new shiny project and add it to this list instead.</p><h2 id=\"current-status\">Current Status</h2>\n<blockquote>\n<p><strong>Blog Status:</strong> Two posts published → Infinite backlog created</p></blockquote>\n<blockquote>\n<p><strong>Documentation Tools:</strong> A collection of text files, a Flatnotes container, Apple Notes, and an unfinished Wiki.js install → Publii for publishing → Shit, I should learn Git to properly use GitHub for version control</p></blockquote>\n<blockquote>\n<p><strong>Current Focus:</strong> Avoiding work by writing about work → Classic procrastination technique</p></blockquote>\n<blockquote>\n<p><strong>Next Steps:</strong> Actually start checking things off this list → Electricity bill suggests urgency</p></blockquote>\n<h2 id=\"whats-next\">What’s Next</h2>\n<p>The hardware documentation post is probably first. Then the network setup, since that’s at least somewhat organized and actually production-stable. After that, we’ll see. Maybe I’ll finally count those containers. Or finally clean up those abandoned Home Assistant entities.</p><p>Or maybe I’ll add more to this list. One or the other.</p><hr>\n<p><em>What’s on your “I really should document this” list? And more importantly - what automations are you running that you’re slightly embarrassed about but refuse to delete because they might be useful someday?</em></p>",
            "image": "https://consolequest.net/media/posts/5/wonderlane-6jA6eVsRJ6Q-unsplash.jpg",
            "author": {
                "name": "Juri Steiner"
            },
            "tags": [
                   "projects",
                   "planning",
                   "homelab",
                   "documentation"
            ],
            "date_published": "2025-11-20T00:14:08+01:00",
            "date_modified": "2025-11-20T00:14:08+01:00"
        },
        {
            "id": "https://consolequest.net/console-quest-1-first-post-ever-no-really.html",
            "url": "https://consolequest.net/console-quest-1-first-post-ever-no-really.html",
            "title": "Console Quest #1: First Post Ever",
            "summary": "Hello World This is awkward. I’m starting a tech blog, but I’ve&hellip;",
            "content_html": "<h1 id=\"hello-world\">Hello World</h1>\n<p>This is awkward. I’m starting a tech blog, but I’ve never actually written a blog post before. Unless you count that LinkedIn rant about Burger King’s Pfand system where none of the staff knew they were supposed to take back reusable cups because apparently everyone just uses paper cups - which, let’s be honest, was peak content and deserved more engagement.</p><p>So here we are. My first real post. Ever.</p><h2 id=\"why-am-i-doing-this\">Why Am I Doing This?</h2>\n<p>Good question. I spend way too much time tinkering with selfhosted services, Docker containers, and automation setups. Currently running way too many containers across various services - I stopped counting after #47, but my electricity bill hasn’t. Honestly, most of this happens in isolation - me, a Dockge interface, and an increasingly complex TrueNAS setup that probably uses more electricity than it should.</p><p>I figured: why not document this chaos? Maybe someone else is on the same journey. Maybe not. Either way, at least I’ll have a record of all the times I broke my setup and somehow fixed it at 2 AM.</p><h2 id=\"the-console-quest-name\">The “Console Quest” Name</h2>\n<p>Yeah, it’s a bit dramatic. But it captures what this actually is - an ongoing quest. Not towards some perfect endpoint, but the journey itself. The tinkering, the next interesting project, the “I wonder if…” that leads to VLANs you didn’t plan to have.</p><p>It’s the quest that’s the point, not the destination.</p><p>Plus, “My Dozens of Containers Homelab Adventures” was too long for a domain name.</p><h2 id=\"why-english\">Why English?</h2>\n<p>But Juri you ask, you are german, why do you write in English, did you feel fancy today?\nActually, there is more than one reason for this.\nFirst and foremost, my brain thinks in english at the moment it comes to tech. 90% of what I read, watch or hear regarding tech is in english. Be it official documentation, Hardware Haven or Two and a Half Admins.\nSecond, I want to hone my english skills. Reading is good, but actually putting out something will hopefully do me some good in that regard.\nLast but not least, if I actually want to have a glimpse of hope at least someone is reading this, I better write it in some kind of “universal language”. And like it or not, that has to be english.</p><h2 id=\"but-youre-using-ai-right\">But you’re using AI, right?</h2>\n<p>Yeah, of course I am. I also use autocorrect. And a computer. I’m not gonna write my posts by hand, like a caveman. But while you’re asking: I write my posts myself, but heavily use AI to correct, structure and overall iterate over the posts. I also use it for research and for analysis.</p><h2 id=\"what-this-blog-will-be\">What This Blog Will Be</h2>\n<p>Honestly? Documentation of my ongoing homelab journey:</p><blockquote>\n<p><strong>Infrastructure Deep Dives:</strong> How I actually set things up → The choices, trade-offs, and why it works (or doesn’t)</p></blockquote>\n<blockquote>\n<p><strong>Home Automation Reality:</strong> Automations that save money and ones that… exist → Home Assistant’s messy truth</p></blockquote>\n<blockquote>\n<p><strong>Half-Finished Projects:</strong> Network segmentation plans, storage migrations, the things I started → Progress updates and lessons learned  </p></blockquote>\n<blockquote>\n<p><strong>“This Broke at 2 AM” Stories:</strong> Real troubleshooting → What went wrong and how I fixed it</p></blockquote>\n<blockquote>\n<p><strong>The Ambitious Ideas:</strong> Logging, monitoring, security → Projects that sound enterprise but it’s just my basement</p></blockquote>\n<p>No promises on posting schedule. Things will get documented when they’re ready - or when they break badly enough that I need to write it down.</p><h2 id=\"why-publii-and-not-ghost\">Why Publii (And Not Ghost)?</h2>\n<p>Speaking of services - this blog is powered by Publii, which is ironic since I literally have Ghost running in my homelab. But after spending my nights managing containers and configs, sometimes you just want a desktop app that generates static files and doesn’t require a database.</p><p>Don’t judge me! Doing it this way dramatically increases the likelihood of this staying up.</p><h2 id=\"current-setup\">Current Setup</h2>\n<p>Since we’re talking infrastructure, here’s what’s currently running this whole operation:</p><blockquote>\n<p><strong>Blog Platform:</strong> Publii static generator → Desktop app, no database drama</p></blockquote>\n<blockquote>\n<p><strong>Hosting:</strong> GitHub Pages → Free, reliable, plays nice with custom domains  </p></blockquote>\n<blockquote>\n<p><strong>Domain:</strong> consolequest.net → Because “MyContainersAreMultiplying.com” was taken</p></blockquote>\n<blockquote>\n<p><strong>Theme:</strong> Mono → Clean, fast, doesn’t get in the way of the content</p></blockquote>\n<blockquote>\n<p><strong>Homelab:</strong> TrueNAS Scale + Dockge → Where the real magic (and chaos) happens</p></blockquote>\n<h2 id=\"whats-next\">What’s Next</h2>\n<p>I’m planning to document my current stack - hardware, network, the services that work, the projects I started and abandoned. Maybe explain why certain choices made sense (like Dockge over Portainer). Probably write about the things that broke and how I fixed them.</p><p>We’ll see how long this lasts. My track record with “I’ll definitely document this properly” projects is a mixed bag.</p><p>But hey, at least I finally started.</p><hr>\n<p><em>Since I have literally zero readers right now, I’ll just say: if you somehow found this, hello! What’s running in your homelab? I’d love to hear about your own console quest adventures.</em></p>",
            "image": "https://consolequest.net/media/posts/2/matthieu-beaumont-iYnpYeyu57k-unsplash.jpg",
            "author": {
                "name": "Juri Steiner"
            },
            "tags": [
                   "truenas",
                   "selfhosting",
                   "introduction",
                   "homelab",
                   "docker"
            ],
            "date_published": "2025-05-24T23:43:13+02:00",
            "date_modified": "2025-11-22T20:43:20+01:00"
        }
    ]
}
